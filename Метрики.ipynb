{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5SP39p-UH4nY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Создание csv файла, чтобы посчитать метрики"
      ],
      "metadata": {
        "id": "hwoFY9hdOdpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# здесь восстанавливаем id для raw файлов\n",
        "def add_ids_to_intents(intent_file_path, id_file_path, output_file_path):\n",
        "    with open(intent_file_path, 'r', encoding='utf-8') as intent_file:\n",
        "        intent_lines = intent_file.readlines()\n",
        "    with open(id_file_path, 'r', encoding='utf-8') as id_file:\n",
        "        id_lines = id_file.readlines()\n",
        "    ids = [re.match(r'#\\s*id:\\s*(\\S+)', line).group(1) for line in id_lines if re.match(r'#\\s*id:', line)]\n",
        "    intent_indices = [i for i, line in enumerate(intent_lines) if line.startswith('# intent =')]\n",
        "    if len(ids) != len(intent_indices):\n",
        "        raise ValueError(f\"ID ({len(ids)}) не совпадают с интентами ({len(intent_indices)})\")\n",
        "    output_lines = []\n",
        "    id_index = 0\n",
        "    for i, line in enumerate(intent_lines):\n",
        "        if line.startswith('# intent ='):\n",
        "            output_lines.append(f'# id: {ids[id_index]}\\n')\n",
        "            id_index += 1\n",
        "        output_lines.append(line)\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "        output_file.writelines(output_lines)\n",
        "add_ids_to_intents('cities_test_adapt.raw_0.conll', 'zara.txt', 'output.conll')"
      ],
      "metadata": {
        "id": "NDVcM5ipP24l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "def parse_annotated_file(filepath):\n",
        "    data = {}\n",
        "    current_id = None\n",
        "    current_intent = None\n",
        "    current_slots = []\n",
        "    intent_pattern = re.compile(r'#\\s*intent\\s*[:=]\\s*(.+)', re.IGNORECASE)\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith('# id:'):\n",
        "                current_id = line.split(':', 1)[1].strip()\n",
        "                current_slots = []\n",
        "            elif line.lower().startswith('# intent'):\n",
        "                match = intent_pattern.match(line)\n",
        "                if match:\n",
        "                    current_intent = match.group(1).strip()\n",
        "            elif line and not line.startswith('#'):\n",
        "                parts = line.split('\\t')\n",
        "                if len(parts) >= 4:\n",
        "                    slot_label = parts[3]\n",
        "                    current_slots.append(slot_label)\n",
        "            elif line == '' and current_id:\n",
        "                data[current_id] = {\n",
        "                    'intent': current_intent,\n",
        "                    'slots': ' '.join(current_slots)\n",
        "                }\n",
        "                current_id = None\n",
        "                current_intent = None\n",
        "                current_slots = []\n",
        "        if current_id:\n",
        "            data[current_id] = {\n",
        "                'intent': current_intent,\n",
        "                'slots': ' '.join(current_slots)\n",
        "            }\n",
        "    return data\n",
        "def create_comparison_csv(gold_file, pred_file, output_csv):\n",
        "    gold_data = parse_annotated_file(gold_file)\n",
        "    pred_data = parse_annotated_file(pred_file)\n",
        "    rows = []\n",
        "    for example_id in gold_data:\n",
        "        row = {\n",
        "            'id': example_id,\n",
        "            'intents_gold': gold_data[example_id]['intent'],\n",
        "            'slots_gold': gold_data[example_id]['slots'],\n",
        "            'intents_pred': pred_data.get(example_id, {}).get('intent', ''),\n",
        "            'slots_pred': pred_data.get(example_id, {}).get('slots', '')\n",
        "        }\n",
        "        rows.append(row)\n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_csv(output_csv, index=False, encoding='utf-8')\n",
        "create_comparison_csv('ru.test_adapt.conll', 'nlu.xsid_test_adapt.out', 'comparison_test_adapt.csv')"
      ],
      "metadata": {
        "id": "sXPRKF-y5HV2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pandas.api.types\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, intent_column_name: str, slots_column_name: str) -> float:\n",
        "    '''\n",
        "    Evaluate the joint performance of intent classification and slot filling using F1 scores.\n",
        "\n",
        "    Computes the weighted F1-score for intent classification, the weighted F1-score for\n",
        "    slot filling, and returns their average. This metric is commonly used in task-oriented\n",
        "    dialogue systems evaluation.\n",
        "\n",
        "    # This example doctest works for intent_detection_and_slot_filling_f1_avg:\n",
        "    >>> import pandas as pd\n",
        "    >>> y_pred = pd.DataFrame.from_dict({'id': [1, 2], 'intent': ['BookRestaurant', 'ScheduleAlarm'], 'slots': ['O B-location I-location B-date', 'B-date O O']})\n",
        "    >>> y_true = pd.DataFrame.from_dict({'id': [1, 2], 'intent': ['BookRestaurant', 'ScheduleAlarm'], 'slots': ['O B-location I-location B-date', 'B-date I-date O']})\n",
        "    >>> score(y_true.copy(), y_pred.copy(), 'id', 'intent', 'slots')\n",
        "    0.88...\n",
        "    '''\n",
        "\n",
        "    del solution[row_id_column_name]\n",
        "    del submission[row_id_column_name]\n",
        "\n",
        "    # Calculate intent F1 score\n",
        "    intent_f1 = f1_score(solution[intent_column_name],\n",
        "                         submission[intent_column_name],\n",
        "                         average='weighted')\n",
        "    print(f\"Intents Metric = {intent_f1}\")\n",
        "\n",
        "    # Calculate slot F1 score\n",
        "    gold_slots = []\n",
        "    system_slots = []\n",
        "\n",
        "    slot_f1 = 0\n",
        "    for gold_slot_str, system_slot_str in zip(solution[slots_column_name], submission[slots_column_name]):\n",
        "      try:\n",
        "        slot_f1 += f1_score(gold_slot_str.split(), system_slot_str.split(), average='weighted')\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "    slot_f1 = slot_f1/len(solution)\n",
        "\n",
        "    # slot_f1 = f1_score(gold_slots, system_slots, average='weighted')\n",
        "\n",
        "    # Calculate average metric\n",
        "    avg_f1 = (intent_f1 + slot_f1) / 2\n",
        "\n",
        "    print(f\"Slots Metric = {slot_f1}\")\n",
        "\n",
        "    return avg_f1\n",
        "\n",
        "\n",
        "comparison = pd.read_csv(\"comparison_vosk.csv\")\n",
        "\n",
        "solution = comparison[['id', 'intents_gold', 'slots_gold']]\n",
        "solution = solution.rename(columns={'intents_gold': 'intents', 'slots_gold': 'slots'})\n",
        "submission = comparison[['id', 'intents_pred', 'slots_pred']]\n",
        "submission = submission.rename(columns={'intents_pred': 'intents', 'slots_pred': 'slots'})\n",
        "\n",
        "score(solution, submission, 'id', 'intents', 'slots')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cbbrmI4oblM",
        "outputId": "e340a6ea-893a-488b-9a35-73ec77033598",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intents Metric = 0.9488236336600104\n",
            "Slots Metric = 0.2806627216408447\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6147431776504275"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}