{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gigaam"
      ],
      "metadata": {
        "id": "mBEKARV82tAt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me66GFwT0ABG"
      },
      "source": [
        "### Installing reqs and downloading examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PlM9MI70iTIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27cd822e-0d3b-400a-bf55-bfdae83975a0",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/salute-developers/GigaAM.git\n",
            "  Cloning https://github.com/salute-developers/GigaAM.git to /tmp/pip-req-build-_deucscs\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/salute-developers/GigaAM.git /tmp/pip-req-build-_deucscs\n",
            "  Resolved https://github.com/salute-developers/GigaAM.git to commit 2dfdad6195286784b496e6ec8d08e4de3b07313b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hydra-core<=1.3.2 (from gigaam==0.1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gigaam==0.1.0) (2.0.2)\n",
            "Requirement already satisfied: omegaconf<=2.3.0 in /usr/local/lib/python3.11/dist-packages (from gigaam==0.1.0) (2.3.0)\n",
            "Collecting pydub<=0.25.1 (from gigaam==0.1.0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece<=0.2.0 in /usr/local/lib/python3.11/dist-packages (from gigaam==0.1.0) (0.2.0)\n",
            "Collecting torch<=2.5.1 (from gigaam==0.1.0)\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchaudio<=2.5.1 (from gigaam==0.1.0)\n",
            "  Downloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting onnx==1.17.0 (from gigaam==0.1.0)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime==1.17.3 (from gigaam==0.1.0)\n",
            "  Downloading onnxruntime-1.17.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gigaam==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx==1.17.0->gigaam==0.1.0) (5.29.4)\n",
            "Collecting coloredlogs (from onnxruntime==1.17.3->gigaam==0.1.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.17.3->gigaam==0.1.0) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.17.3->gigaam==0.1.0) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.17.3->gigaam==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core<=1.3.2->gigaam==0.1.0) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<=2.3.0->gigaam==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<=2.5.1->gigaam==0.1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<=2.5.1->gigaam==0.1.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<=2.5.1->gigaam==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.5.1->gigaam==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<=2.5.1->gigaam==0.1.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<=2.5.1->gigaam==0.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<=2.5.1->gigaam==0.1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<=2.5.1->gigaam==0.1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<=2.5.1->gigaam==0.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<=2.5.1->gigaam==0.1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<=2.5.1->gigaam==0.1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<=2.5.1->gigaam==0.1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<=2.5.1->gigaam==0.1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<=2.5.1->gigaam==0.1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<=2.5.1->gigaam==0.1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<=2.5.1->gigaam==0.1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<=2.5.1->gigaam==0.1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch<=2.5.1->gigaam==0.1.0)\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime==1.17.3->gigaam==0.1.0) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.17.3->gigaam==0.1.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<=2.5.1->gigaam==0.1.0) (3.0.2)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.17.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gigaam\n",
            "  Building wheel for gigaam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gigaam: filename=gigaam-0.1.0-py3-none-any.whl size=22399 sha256=59441d759619f0d6b1d3c0f9a9788772a721330b046eba1f0e39b736aaeea7cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9_lg5_t0/wheels/40/c7/e4/49fa57736263c77f6f331f342a67faa096dbac7114efa81e3a\n",
            "Successfully built gigaam\n",
            "Installing collected packages: pydub, triton, onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, coloredlogs, onnxruntime, nvidia-cusolver-cu12, torch, torchaudio, gigaam\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed coloredlogs-15.0.1 gigaam-0.1.0 humanfriendly-10.0 hydra-core-1.3.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.17.0 onnxruntime-1.17.3 pydub-0.25.1 torch-2.5.1 torchaudio-2.5.1 triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "# If package is not installed\n",
        "! pip install git+https://github.com/salute-developers/GigaAM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GSE4HSfr1P0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd753c7a-cec1-4013-c835-159b56f6c4cf",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-24 05:52:58--  https://cdn.chatwm.opensmodel.sberdevices.ru/GigaAM/example.wav\n",
            "Resolving cdn.chatwm.opensmodel.sberdevices.ru (cdn.chatwm.opensmodel.sberdevices.ru)... 151.236.71.248\n",
            "Connecting to cdn.chatwm.opensmodel.sberdevices.ru (cdn.chatwm.opensmodel.sberdevices.ru)|151.236.71.248|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 361324 (353K) [audio/x-wav]\n",
            "Saving to: ‘example.wav’\n",
            "\n",
            "example.wav         100%[===================>] 352.86K   720KB/s    in 0.5s    \n",
            "\n",
            "2025-05-24 05:53:00 (720 KB/s) - ‘example.wav’ saved [361324/361324]\n",
            "\n",
            "--2025-05-24 05:53:00--  https://cdn.chatwm.opensmodel.sberdevices.ru/GigaAM/long_example.wav\n",
            "Resolving cdn.chatwm.opensmodel.sberdevices.ru (cdn.chatwm.opensmodel.sberdevices.ru)... 151.236.71.248\n",
            "Connecting to cdn.chatwm.opensmodel.sberdevices.ru (cdn.chatwm.opensmodel.sberdevices.ru)|151.236.71.248|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2280109 (2.2M) [audio/x-wav]\n",
            "Saving to: ‘long_example.wav’\n",
            "\n",
            "long_example.wav    100%[===================>]   2.17M  2.71MB/s    in 0.8s    \n",
            "\n",
            "2025-05-24 05:53:01 (2.71 MB/s) - ‘long_example.wav’ saved [2280109/2280109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Downloading wavs for examples\n",
        "!wget https://cdn.chatwm.opensmodel.sberdevices.ru/GigaAM/example.wav\n",
        "!wget https://cdn.chatwm.opensmodel.sberdevices.ru/GigaAM/long_example.wav"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg7VpjMO1Gc5",
        "outputId": "6a839fea-e8b1-443c-b6df-81d76cd108cb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!apt install ffmpeg -y"
      ],
      "metadata": {
        "id": "ItMQvNsV3V48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "root_dir = '/content/drive/MyDrive/Курсовая работа_2025/озвучка_valid_adapt' # или озвучка_test_adapt\n",
        "\n",
        "audio_exts = ['.mp3', '.m4a', '.ogg', '.flac', '.aac', '.wma']\n",
        "\n",
        "for subdir, _, files in os.walk(root_dir):\n",
        "    for file in files:\n",
        "        ext = os.path.splitext(file)[-1].lower()\n",
        "        if ext in audio_exts:\n",
        "            src_path = os.path.join(subdir, file)\n",
        "            dst_path = os.path.splitext(src_path)[0] + '.wav'\n",
        "\n",
        "            try:\n",
        "                sound = AudioSegment.from_file(src_path)\n",
        "                sound.export(dst_path, format=\"wav\")\n",
        "                os.remove(src_path)\n",
        "                print(f\"конвертировано и удалено: {src_path} → {dst_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"ошибка {src_path}: {e}\")"
      ],
      "metadata": {
        "id": "ZJdl5FLM3Wgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIvec0280O64"
      },
      "source": [
        "## Speech Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xCgbSPkViZpF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "from typing import Dict\n",
        "\n",
        "import gigaam\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "R2aUkZbG8fJ6",
        "outputId": "76dc4c83-b6c3-4e42-c4a4-c30408f66840",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 444M/444M [00:22<00:00, 20.4MiB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'какая погода в москве'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# model = gigaam.load_model(\n",
        "#     \"ctc\",  # GigaAM-V2 CTC model\n",
        "#     fp16_encoder=True,  # to use fp16 encoder weights - GPU only\n",
        "#     use_flash=False,  # disable flash attention - colab does not support it\n",
        "# )\n",
        "# model.transcribe(\"sample.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nPc8flc1U3d"
      },
      "outputs": [],
      "source": [
        "# для test\n",
        "from pathlib import Path\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_root = Path(\"/content/drive/MyDrive/Курсовая работа_2025/озвучка_test_adapt\") # путь к файлу\n",
        "\n",
        "output_root = Path(\"/content/drive/MyDrive/звук_gigaam\") # путь к файлу\n",
        "output_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "model = gigaam.load_model(\"rnnt\", device=\"cpu\")\n",
        "\n",
        "for voice_dir in input_root.iterdir():\n",
        "    if voice_dir.is_dir():\n",
        "        print(f\"\\nГруппа: {voice_dir.name}\")\n",
        "        all_lines = []\n",
        "\n",
        "        # ищем .wav файлы\n",
        "        wav_files = list(voice_dir.rglob(\"*.wav\"))\n",
        "        if not wav_files:\n",
        "            print(f\"нет .wav файлов в {voice_dir}\")\n",
        "            continue\n",
        "\n",
        "        for wav_file in tqdm(wav_files, desc=f\"{voice_dir.name}\"):\n",
        "            file_id = wav_file.stem\n",
        "\n",
        "            try:\n",
        "                text = model.transcribe(str(wav_file))\n",
        "                if text.strip():\n",
        "                    all_lines.append(f\"# id: {file_id}\\n{text.strip()}\\n\")\n",
        "                else:\n",
        "                    print(f\"пусто: {file_id}\")\n",
        "            except Exception as e:\n",
        "                print(f\"ошибка в {wav_file.name}: {e}\")\n",
        "\n",
        "        if all_lines:\n",
        "            output_path = output_root / f\"{voice_dir.name}.conll\"\n",
        "            with output_path.open(\"w\", encoding=\"utf-8\") as out_f:\n",
        "                out_f.write(\"\\n\".join(all_lines))\n",
        "            print(output_path.name)\n",
        "        else:\n",
        "            print(f\"нет данных для: {voice_dir.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# для valid\n",
        "input_root = Path(\"/content/drive/MyDrive/Курсовая работа_2025/озвучка_valid_adapt\")\n",
        "output_root = Path(\"/content/drive/MyDrive/звук_gigaam\")\n",
        "output_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "all_lines = []\n",
        "\n",
        "wav_files = list(input_root.glob(\"*.wav\"))\n",
        "if not wav_files:\n",
        "    print(f\"нет .wav файлов в {input_root}\")\n",
        "else:\n",
        "    for wav_file in tqdm(wav_files):\n",
        "        file_id = wav_file.stem\n",
        "\n",
        "        try:\n",
        "            text = model.transcribe(str(wav_file))\n",
        "            if text.strip():\n",
        "                all_lines.append(f\"# id: {file_id}\\n{text.strip()}\\n\")\n",
        "            else:\n",
        "                print(f\"пусто: {file_id}\")\n",
        "        except Exception as e:\n",
        "            print(f\"ошибка в {wav_file.name}: {e}\")\n",
        "\n",
        "    if all_lines:\n",
        "        output_path = output_root / \"valid_gigaam.conll\"\n",
        "        with output_path.open(\"w\", encoding=\"utf-8\") as out_f:\n",
        "            out_f.write(\"\\n\".join(all_lines))\n",
        "        print(f\"\\n сохранили: {output_path.name}\")\n",
        "    else:\n",
        "        print(f\"нет данных для: {voice_dir.name}\")"
      ],
      "metadata": {
        "id": "o1dt3OF3933P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78WAYQTa14Qs"
      },
      "source": [
        "### Long-Form Speech Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvQdrpqG39kQ"
      },
      "outputs": [],
      "source": [
        "!pip install gigaam[longform]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riG4tjcH8fJ7"
      },
      "source": [
        "* For long-form inference:\n",
        "  * generate [Hugging Face API token](https://huggingface.co/docs/hub/security-tokens)\n",
        "  * accept the conditions to access [pyannote/voice-activity-detection](https://huggingface.co/pyannote/voice-activity-detection) files and content\n",
        "  * accept the conditions to access [pyannote/segmentation](https://huggingface.co/pyannote/segmentation) files and content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlpX1XOX4vGw"
      },
      "outputs": [],
      "source": [
        "os.environ[\"HF_TOKEN\"] = \"<HF_TOKEN>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI_tb_N918FS",
        "outputId": "db002337-fdd4-4fba-95e8-802e010d5303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:00:00 - 00:16:83]: вечерня отошла давно но в кельях тихо и темно уже и сам игумен строгий свои молитвы прекратил и кости ветхие склонил перекрестясь на одр убогий кругом и сон и тишина но церкви дверь отворена\n",
            "[00:17:10 - 00:32:61]: трепещет луч лампады и тускло озаряет он и темную живопись икон и позлощенные оклады и раздается в тишине то тяжкий вздох то шепот важный и мрачно дремлет в вышине старинный свод\n",
            "[00:32:95 - 00:49:33]: глухой и влажный стоят за клиросом чернец и грешник неподвижны оба и шепот их как глаз из гроба и грешник бледен как мертвец монах несчастный полно перестань\n",
            "[00:49:82 - 01:05:74]: ужасна исповедь злодея заплачена тобою дань тому кто в злобе пламенея лукаво грешника блюдет и к вечной гибели ведет смирись опомнись время время раскаянье покров\n",
            "[01:05:97 - 01:10:90]: я разрешу тебя грехов сложи мучительное бремя\n"
          ]
        }
      ],
      "source": [
        "model = gigaam.load_model(\"ctc\", use_flash=False)\n",
        "recognition_result = model.transcribe_longform(\"long_example.wav\")\n",
        "\n",
        "for utterance in recognition_result:\n",
        "    transcription = utterance[\"transcription\"]\n",
        "    start, end = utterance[\"boundaries\"]\n",
        "    print(f\"[{gigaam.format_time(start)} - {gigaam.format_time(end)}]: {transcription}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywEjYaAe3BMU"
      },
      "source": [
        "## Emotion recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWsJ2RuG3HNB",
        "outputId": "6d1f8abb-9fb0-4c28-c5e3-c21413a22796"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 924M/924M [02:04<00:00, 7.78MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "angry: 0.000, sad: 0.002, neutral: 0.923, positive: 0.074\n"
          ]
        }
      ],
      "source": [
        "model = gigaam.load_model(\"emo\")\n",
        "emotion2prob: Dict[str, int] = model.get_probs(\"example.wav\")\n",
        "\n",
        "print(\", \".join([f\"{emotion}: {prob:.3f}\" for emotion, prob in emotion2prob.items()]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EBcRVcC3P2E"
      },
      "source": [
        "## GigaAM embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y2mEAGU3TYN",
        "outputId": "ae488719-df9f-4318-ecf7-56c95a87a4ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 887M/887M [03:21<00:00, 4.62MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-0.2829,  0.3638,  0.4520,  ..., -0.4743, -0.4033, -0.2417],\n",
            "         [ 0.1611, -0.5006, -0.0584,  ..., -0.6239, -0.2320, -0.2054],\n",
            "         [-1.1849, -1.0029, -0.6111,  ..., -0.5137, -0.3737, -0.2654],\n",
            "         ...,\n",
            "         [ 0.0181, -0.3763, -0.8959,  ...,  0.1716,  0.0556,  0.1298],\n",
            "         [ 0.2690, -0.0654, -0.5020,  ..., -1.4432, -1.4827, -1.4490],\n",
            "         [-1.5650, -1.6693, -1.2834,  ...,  0.5117,  0.4839,  0.0136]]],\n",
            "       device='cuda:0', grad_fn=<TransposeBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# audio-only pretrained encoder\n",
        "model = gigaam.load_model(\"ssl\", use_flash=False)\n",
        "\n",
        "emb, _ = model.embed_audio(\"example.wav\")\n",
        "print(emb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW8GKJrl3tm7",
        "outputId": "160f4e59-3020-4986-b35e-5c7fa6e105fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-1.0334, -0.2841, -0.3606,  ..., -0.2859, -0.6947, -0.7006],\n",
            "         [-0.4317, -0.0140, -0.9296,  ...,  0.1781,  0.2170, -0.0181],\n",
            "         [-0.9221, -1.1284, -0.6389,  ..., -1.0664, -1.3304, -1.2421],\n",
            "         ...,\n",
            "         [ 0.5749,  0.5176, -0.0996,  ...,  1.7497,  1.8691,  2.1302],\n",
            "         [-0.2919, -0.8087, -1.2554,  ..., -0.7942, -0.7634, -0.7938],\n",
            "         [-1.8086, -2.1976, -2.4012,  ...,  0.8310,  1.0165,  1.0165]]],\n",
            "       device='cuda:0', grad_fn=<TransposeBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# you also can embed audio with CTC- or RNNT-finetuned encoder\n",
        "model = gigaam.load_model(\"ctc\", use_flash=False)\n",
        "\n",
        "emb, _ = model.embed_audio(\"example.wav\")\n",
        "print(emb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je4WAyLgz0Ua"
      },
      "source": [
        "## Export to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tvo_v_iz0Ua",
        "outputId": "4db517e6-7e85-4c01-c4c3-0b21744b8988"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 892M/892M [03:20<00:00, 4.66MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Succesfully ported onnx v2_rnnt_encoder to onnx/v2_rnnt_encoder.onnx.\n",
            "Succesfully ported onnx v2_rnnt_decoder to onnx/v2_rnnt_decoder.onnx.\n",
            "Succesfully ported onnx v2_rnnt_joint to onnx/v2_rnnt_joint.onnx.\n"
          ]
        }
      ],
      "source": [
        "onnx_dir = \"onnx\"\n",
        "model_type = \"rnnt\" # or \"ctc\"\n",
        "\n",
        "model = gigaam.load_model(\n",
        "    model_type,\n",
        "    fp16_encoder=False,  # only fp32 tensors\n",
        "    use_flash=False,  # disable flash attention\n",
        ")\n",
        "model.to_onnx(dir_path=onnx_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL3W76cgz0Ua"
      },
      "source": [
        "### ONNX inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "j_rjvUeJz0Ua",
        "outputId": "2f8a9e71-c5aa-4fb6-89cf-d251eeb7dce3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ничьих не требуя похвал счастлив уж я надеждой сладкой что дева с трепетом любви посмотрит может быть украдкой на песни грешные мои у лукоморья дуб зеленый'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from gigaam.onnx_utils import load_onnx_sessions, transcribe_sample\n",
        "\n",
        "sessions = load_onnx_sessions(onnx_dir, model_type)\n",
        "transcribe_sample(\"example.wav\", model_type, sessions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VOSK\n"
      ],
      "metadata": {
        "id": "ijRTqk9L0au0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vosk pydub\n",
        "!apt-get install -y ffmpeg"
      ],
      "metadata": {
        "id": "ci8fZv8y3-FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wave\n",
        "import json\n",
        "from vosk import Model, KaldiRecognizer"
      ],
      "metadata": {
        "id": "hEQKHCDg4ZNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# путь к нужным папкам\n",
        "input_dir = \"/content/drive/MyDrive/Курсовая работа_2025/озвучка_valid_adapt\"\n",
        "output_root = \"/content/drive/MyDrive/result_valid_adapt\"\n",
        "os.makedirs(output_root, exist_ok=True)\n",
        "\n",
        "# загружаем модель\n",
        "if not os.path.exists('vosk-model-small-ru-0.22'):\n",
        "    !wget https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip\n",
        "    !unzip vosk-model-small-ru-0.22.zip\n",
        "model = Model('vosk-model-small-ru-0.22')\n",
        "\n",
        "# нужен WAV 16kHz mono для vosk\n",
        "def convert_to_wav16k_mono(src_path, dst_path):\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(src_path)\n",
        "        audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)\n",
        "        audio.export(dst_path, format=\"wav\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"ошибка {src_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "for root, _, files in os.walk(input_dir):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.wav', '.mp3', '.m4a', '.flac', '.aac', '.ogg')):\n",
        "            full_path = os.path.join(root, file)\n",
        "            file_id = os.path.splitext(file)[0]\n",
        "\n",
        "\n",
        "            relative_path = os.path.relpath(root, input_dir)\n",
        "            output_folder = os.path.join(output_root, relative_path, file_id)\n",
        "            os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "            temp_path = \"/content/temp.wav\"\n",
        "            print(f\"обработка: {file_id}\")\n",
        "\n",
        "            if not convert_to_wav16k_mono(full_path, temp_path):\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                wf = wave.open(temp_path, 'rb')\n",
        "                rec = KaldiRecognizer(model, wf.getframerate())\n",
        "\n",
        "                results = []\n",
        "                while True:\n",
        "                    data = wf.readframes(4000)\n",
        "                    if len(data) == 0:\n",
        "                        break\n",
        "                    if rec.AcceptWaveform(data):\n",
        "                        res = json.loads(rec.Result())\n",
        "                        results.append(res.get('text', ''))\n",
        "                res = json.loads(rec.FinalResult())\n",
        "                results.append(res.get('text', ''))\n",
        "                final_text = ' '.join(results).strip()\n",
        "                tokens = final_text.split()\n",
        "\n",
        "                output_file = os.path.join(output_folder, f\"{file_id}.conll\")\n",
        "                with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(f\"# id: {file_id}\\n\")\n",
        "                    f.write(f\"# text RU: {final_text}\\n\")\n",
        "                    for idx, token in enumerate(tokens, 1):\n",
        "                        f.write(f\"{idx}\\t{token}\\tO\\n\")\n",
        "\n",
        "                print(f\"сохранили: {output_file}\")\n",
        "            except Exception as e:\n",
        "                print(f\"ошибка {file_id}: {e}\")"
      ],
      "metadata": {
        "id": "Fvf-B9wmamw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_root = Path(\"/content/drive/MyDrive/result_test_adapt\")\n",
        "output_root = Path(\"/content/drive/MyDrive/звук_vosk\")\n",
        "output_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for voice_dir in input_root.iterdir():\n",
        "    if voice_dir.is_dir():\n",
        "        print(f\"\\nГруппа: {voice_dir.name}\")\n",
        "        all_lines = []\n",
        "\n",
        "        conll_files = list(voice_dir.rglob(\"*.conll\"))\n",
        "        if not conll_files:\n",
        "            print(f\".conll файлов в {voice_dir}\")\n",
        "            continue\n",
        "\n",
        "        for file in conll_files:\n",
        "            print(file.relative_to(input_root))\n",
        "            try:\n",
        "                with file.open(encoding=\"utf-8\") as f:\n",
        "                    lines = f.read().splitlines()\n",
        "            except Exception as e:\n",
        "                print(f\"ошибка {file.name}: {e}\")\n",
        "                continue\n",
        "\n",
        "            current_id = None\n",
        "            current_text = None\n",
        "\n",
        "            for line in lines:\n",
        "                if line.startswith(\"# id:\"):\n",
        "                      match = re.search(r'# id:\\s*(?:id\\s*)?(.+)', line)\n",
        "                      if match:\n",
        "                          current_id = match.group(1).strip()\n",
        "                elif line.startswith(\"# text RU:\"):\n",
        "                    current_text = line.split(\":\", 1)[-1].strip()\n",
        "\n",
        "            if current_id and current_text:\n",
        "                all_lines.append(f\"# id: {current_id}\\n{current_text}\\n\")\n",
        "            else:\n",
        "                print(f\"пропуск {file.name}\")\n",
        "\n",
        "        if all_lines:\n",
        "            output_path = output_root / f\"{voice_dir.name}.conll\"\n",
        "            with output_path.open(\"w\", encoding=\"utf-8\") as out_f:\n",
        "                out_f.write(\"\\n\".join(all_lines))\n",
        "            print(f\"сохранили {output_path.name}\")\n",
        "        else:\n",
        "             print(\"ничего нет\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aDjQsbSFknj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_root = Path(\"/content/drive/MyDrive/result_valid_adapt\")\n",
        "output_root = Path(\"/content/drive/MyDrive/звук_vosk\")\n",
        "output_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "output_file = output_root / \"valid_vosk.conll\"\n",
        "\n",
        "all_lines = []\n",
        "\n",
        "conll_files = list(input_root.rglob(\"*.conll\"))\n",
        "if not conll_files:\n",
        "    print(f\".conll файлов в {input_root}\")\n",
        "else:\n",
        "    for file in conll_files:\n",
        "        print(file.relative_to(input_root))\n",
        "        try:\n",
        "            with file.open(encoding=\"utf-8\") as f:\n",
        "                lines = f.read().splitlines()\n",
        "        except Exception as e:\n",
        "            print(f\"ошибка {file.name}: {e}\")\n",
        "            continue\n",
        "\n",
        "        current_id = None\n",
        "        current_text = None\n",
        "\n",
        "        for line in lines:\n",
        "            if line.startswith(\"# id:\"):\n",
        "                match = re.search(r'# id:\\s*(?:id\\s*)?(.+)', line)\n",
        "                if match:\n",
        "                    current_id = match.group(1).strip()\n",
        "            elif line.startswith(\"# text RU:\"):\n",
        "                current_text = line.split(\":\", 1)[-1].strip()\n",
        "\n",
        "        if current_id and current_text:\n",
        "            all_lines.append(f\"# id: {current_id}\\n{current_text}\\n\")\n",
        "        else:\n",
        "            print(f\"пропуск {file.name}\")\n",
        "\n",
        "if all_lines:\n",
        "    with output_file.open(\"w\", encoding=\"utf-8\") as out_f:\n",
        "        out_f.write(\"\\n\".join(all_lines))\n",
        "    print(f\"сохранили {output_file.name}\")\n",
        "else:\n",
        "    print(\"ничего нет\")"
      ],
      "metadata": {
        "id": "G5_ZMzaO2qlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "folder = Path(\"/content/drive/MyDrive/звук_gigaam\")\n",
        "\n",
        "for file_path in folder.glob(\"*.conll\"):\n",
        "    print(file_path.name)\n",
        "    try:\n",
        "        with file_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "            lines = f.readlines()\n",
        "        cleaned_lines = []\n",
        "        for line in lines:\n",
        "            if line.startswith(\"# id:\"):\n",
        "                match = re.search(r'# id:\\s*(?:id\\s*)?(.+)', line)\n",
        "                if match:\n",
        "                    cleaned_line = f\"# id: {match.group(1).strip()}\\n\"\n",
        "                    cleaned_lines.append(cleaned_line)\n",
        "                else:\n",
        "                    cleaned_lines.append(line)\n",
        "            else:\n",
        "                cleaned_lines.append(line)\n",
        "\n",
        "        with file_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "            f.writelines(cleaned_lines)\n",
        "        print(file_path.name)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ошибка {file_path.name}: {e}\")"
      ],
      "metadata": {
        "id": "2ia-Vs4q853N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WER, CER"
      ],
      "metadata": {
        "id": "FTd_Bx495knq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install jiwer"
      ],
      "metadata": {
        "id": "yAtDGkmq5e44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "from jiwer import cer\n",
        "wer = load(\"wer\")\n",
        "wer_score = wer.compute(predictions=predictions, references=references)"
      ],
      "metadata": {
        "id": "mX44fQ2r5hrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vosk_dir = \"/content/drive/MyDrive/звук_gigaam\" # vosk\n",
        "reference_path = \"/content/drive/MyDrive/Курсовая работа_2025/ru.valid_adapt.conll\"\n",
        "wer = load(\"wer\")\n",
        "\n",
        "def parse_predictions(file_path):\n",
        "    preds = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        current_id = None\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith('# id:'):\n",
        "                current_id = line.split(':', 1)[1].strip()\n",
        "            elif line and current_id:\n",
        "                preds[current_id] = line\n",
        "                current_id = None\n",
        "    return preds\n",
        "def parse_references(file_path):\n",
        "    refs = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        current_id = None\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith('# id:'):\n",
        "                current_id = line.split(':', 1)[1].strip()\n",
        "            elif line.startswith('# text RU:'):\n",
        "                if current_id:\n",
        "                    refs[current_id] = line.split(':', 1)[1].strip()\n",
        "    return refs\n",
        "\n",
        "#  WER для пары prediction + reference\n",
        "def compute_wer(pred_file, ref_dict):\n",
        "    preds = parse_predictions(pred_file)\n",
        "    matched_preds = []\n",
        "    matched_refs = []\n",
        "    for ex_id in preds:\n",
        "        if ex_id in ref_dict:\n",
        "            matched_preds.append(preds[ex_id])\n",
        "            matched_refs.append(ref_dict[ex_id])\n",
        "    if not matched_preds:\n",
        "        print(f\"нет совпадений в {pred_file}\")\n",
        "        return None\n",
        "    score = wer.compute(predictions=matched_preds, references=matched_refs)\n",
        "    print(f\"{os.path.basename(pred_file)}: WER = {score:.4f}\")\n",
        "    return score\n",
        "ref_dict = parse_references(reference_path)\n",
        "results = {}\n",
        "for fname in os.listdir(vosk_dir):\n",
        "        fpath = os.path.join(vosk_dir, fname)\n",
        "        score = compute_wer(fpath, ref_dict)\n",
        "        if score is not None:\n",
        "            results[fname] = score"
      ],
      "metadata": {
        "id": "5CqJ-8mmOdp7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vosk_dir = \"/content/drive/MyDrive/звук_vosk\"\n",
        "reference_path = \"/content/drive/MyDrive/Курсовая работа_2025/ru.test_adapt.conll\"\n",
        "\n",
        "def parse_predictions(file_path):\n",
        "    preds = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        current_id = None\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith('# id:'):\n",
        "                current_id = line.split(':', 1)[1].strip()\n",
        "            elif line and current_id:\n",
        "                preds[current_id] = line\n",
        "                current_id = None\n",
        "    return preds\n",
        "def parse_references(file_path):\n",
        "    refs = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        current_id = None\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith('# id:'):\n",
        "                current_id = line.split(':', 1)[1].strip()\n",
        "            elif line.startswith('# text RU:'):\n",
        "                if current_id:\n",
        "                    refs[current_id] = line.split(':', 1)[1].strip()\n",
        "    return refs\n",
        "# CER для пары prediction + reference\n",
        "def compute_wer(pred_file, ref_dict):\n",
        "    preds = parse_predictions(pred_file)\n",
        "    matched_preds = []\n",
        "    matched_refs = []\n",
        "    for ex_id in preds:\n",
        "        if ex_id in ref_dict:\n",
        "            matched_preds.append(preds[ex_id])\n",
        "            matched_refs.append(ref_dict[ex_id])\n",
        "    if not matched_preds:\n",
        "        print(f\"нет совпадений в {pred_file}\")\n",
        "        return None\n",
        "    score = cer(matched_refs, matched_preds)\n",
        "    print(f\"{os.path.basename(pred_file)}: CER = {score:.4f}\")\n",
        "    return score\n",
        "ref_dict = parse_references(reference_path)\n",
        "results = {}\n",
        "for fname in os.listdir(vosk_dir):\n",
        "        fpath = os.path.join(vosk_dir, fname)\n",
        "        score = compute_wer(fpath, ref_dict)\n",
        "        if score is not None:\n",
        "            results[fname] = score"
      ],
      "metadata": {
        "id": "ZPlEZ5UTdbhC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "78WAYQTa14Qs",
        "ywEjYaAe3BMU",
        "1EBcRVcC3P2E",
        "je4WAyLgz0Ua",
        "NL3W76cgz0Ua"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}